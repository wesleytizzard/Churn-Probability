{"cells":[{"cell_type":"markdown","metadata":{"id":"87Bve6QZggnT"},"source":["# SUP ML 3 - PREDICT"]},{"cell_type":"markdown","metadata":{"id":"jTEOHHidYOV-"},"source":["# Librerias"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"5Rkor61lYTQX"},"outputs":[],"source":["# Datos\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","# Preprocessing\n","from unidecode import unidecode\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Visualizacion\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# inhabilita warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"KohbVrqkJIKU"},"source":["# Carga modelo"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"StbMbwFVMjQL"},"outputs":[{"name":"stdout","output_type":"stream","text":["MODEL: CatBoostClassifier \n"," Model features list: \n"," ['rev', 'mou', 'totmrc', 'change_mou', 'drop_vce', 'drop_dat', 'blck_vce', 'blck_dat', 'unan_vce', 'unan_dat', 'plcd_dat', 'recv_vce', 'recv_sms', 'custcare', 'ccrndmou', 'threeway', 'mou_cvce', 'mou_cdat', 'mou_rvce', 'owylis_vce', 'mouowylisv', 'iwylis_vce', 'mouiwylisv', 'peak_vce', 'peak_dat', 'mou_peav', 'mou_pead', 'opk_vce', 'opk_dat', 'mou_opkv', 'drop_blk', 'complete', 'callfwdv', 'callwait', 'months', 'uniqsubs', 'actvsubs', 'new_cell', 'asl_flag', 'adjrev', 'adjmou', 'adjqty', 'avgrev', 'avgmou', 'avgqty', 'avg3mou', 'avg3qty', 'avg3rev', 'avg6rev', 'hnd_price', 'lor', 'adults', 'income', 'numbcars', 'eqpdays', 'num_kids', 'crclscod_A', 'crclscod_B', 'crclscod_C', 'crclscod_D', 'crclscod_E', 'crclscod_OTHER', 'crclscod_Z', 'prizm_social_one_C', 'prizm_social_one_R', 'prizm_social_one_S', 'prizm_social_one_T', 'prizm_social_one_U', 'prizm_social_one_UNKNOWN', 'area_ATLANTIC SOUTH', 'area_CALIFORNIA NORTH', 'area_CENTRAL/SOUTH TEXAS', 'area_CHICAGO', 'area_DALLAS', 'area_DC/MARYLAND/VIRGINIA', 'area_GREAT LAKES', 'area_HOUSTON', 'area_LOS ANGELES', 'area_MIDWEST', 'area_NEW ENGLAND', 'area_NEW YORK CITY', 'area_NORTH FLORIDA', 'area_NORTHWEST/ROCKY MOUNTAIN', 'area_OHIO', 'area_PHILADELPHIA', 'area_SOUTH FLORIDA', 'area_SOUTHWEST', 'area_TENNESSEE', 'dualband_N', 'dualband_UNKNOWN', 'dualband_Y', 'refurb_new_R', 'hnd_webcap_UNKNOWN', 'hnd_webcap_WC', 'hnd_webcap_WCMB', 'ownrent_O', 'dwlltype_M', 'dwlltype_S', 'dwlltype_UNKNOWN', 'marital_A', 'marital_B', 'marital_M', 'marital_S', 'marital_U', 'HHstatin_A', 'HHstatin_B', 'HHstatin_C', 'HHstatin_I', 'HHstatin_UNKNOWN', 'dwllsize_A', 'dwllsize_B', 'dwllsize_UNKNOWN', 'ethnic_F', 'ethnic_G', 'ethnic_H', 'ethnic_I', 'ethnic_J', 'ethnic_N', 'ethnic_O', 'ethnic_OTHER', 'ethnic_S', 'ethnic_U', 'ethnic_Z', 'creditcd_N']\n"]}],"source":["model = pickle.load(open('C:/Users/aalei/Desktop/Marzo 2024/ENTREGA2_COPY/model/here_you_save_model_and_preprocessors.txt', 'rb'))\n","print('MODEL: CatBoostClassifier','\\n','Model features list:','\\n',model.feature_names_)"]},{"cell_type":"markdown","metadata":{"id":"9MEmBvLvJA-s"},"source":["# Carga PREDICT dataset"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Rows:  10000   Columns:  99 \n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rev</th>\n","      <th>mou</th>\n","      <th>totmrc</th>\n","      <th>da</th>\n","      <th>ovrmou</th>\n","      <th>ovrrev</th>\n","      <th>vceovr</th>\n","      <th>datovr</th>\n","      <th>roam</th>\n","      <th>change_mou</th>\n","      <th>...</th>\n","      <th>forgntvl</th>\n","      <th>ethnic</th>\n","      <th>kid0_2</th>\n","      <th>kid3_5</th>\n","      <th>kid6_10</th>\n","      <th>kid11_15</th>\n","      <th>kid16_17</th>\n","      <th>creditcd</th>\n","      <th>eqpdays</th>\n","      <th>Customer_ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30.8350</td>\n","      <td>136.75</td>\n","      <td>29.99</td>\n","      <td>0.2475</td>\n","      <td>1.25</td>\n","      <td>0.500</td>\n","      <td>0.5</td>\n","      <td>0.000</td>\n","      <td>0.0975</td>\n","      <td>48.25</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>Y</td>\n","      <td>216.0</td>\n","      <td>1090001</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>35.8475</td>\n","      <td>352.75</td>\n","      <td>24.27</td>\n","      <td>0.4950</td>\n","      <td>23.25</td>\n","      <td>9.285</td>\n","      <td>8.7</td>\n","      <td>0.585</td>\n","      <td>1.8000</td>\n","      <td>-352.75</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>N</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>N</td>\n","      <td>101.0</td>\n","      <td>1090002</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 99 columns</p>\n","</div>"],"text/plain":["       rev     mou  totmrc      da  ovrmou  ovrrev  vceovr  datovr    roam  \\\n","0  30.8350  136.75   29.99  0.2475    1.25   0.500     0.5   0.000  0.0975   \n","1  35.8475  352.75   24.27  0.4950   23.25   9.285     8.7   0.585  1.8000   \n","\n","   change_mou  ...  forgntvl  ethnic  kid0_2  kid3_5  kid6_10  kid11_15  \\\n","0       48.25  ...       1.0       U       U       U        U         U   \n","1     -352.75  ...       0.0       N       U       U        U         U   \n","\n","   kid16_17  creditcd  eqpdays  Customer_ID  \n","0         U         Y    216.0      1090001  \n","1         U         N    101.0      1090002  \n","\n","[2 rows x 99 columns]"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["sample_predict = pd.read_csv('C:/Users/aalei/Desktop/Marzo 2024/ENTREGA2_COPY/data/telecom_churn_PREDICT.csv') #,index_col=0\n","print('Rows: ', sample_predict.shape[0], '  Columns: ', sample_predict.shape[1], '\\n')\n","sample_predict.head(2)"]},{"cell_type":"markdown","metadata":{"id":"3DbfLkADLbc0"},"source":["# ML Preprocessing"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicated rows in Customer_ID: 0\n","Updated index to Customer_ID\n","Rows:  10000   Columns:  98\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rev</th>\n","      <th>mou</th>\n","      <th>totmrc</th>\n","      <th>da</th>\n","      <th>ovrmou</th>\n","      <th>ovrrev</th>\n","      <th>vceovr</th>\n","      <th>datovr</th>\n","      <th>roam</th>\n","      <th>change_mou</th>\n","      <th>...</th>\n","      <th>dwllsize</th>\n","      <th>forgntvl</th>\n","      <th>ethnic</th>\n","      <th>kid0_2</th>\n","      <th>kid3_5</th>\n","      <th>kid6_10</th>\n","      <th>kid11_15</th>\n","      <th>kid16_17</th>\n","      <th>creditcd</th>\n","      <th>eqpdays</th>\n","    </tr>\n","    <tr>\n","      <th>Customer_ID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1090001</th>\n","      <td>30.8350</td>\n","      <td>136.75</td>\n","      <td>29.99</td>\n","      <td>0.2475</td>\n","      <td>1.25</td>\n","      <td>0.500</td>\n","      <td>0.5</td>\n","      <td>0.000</td>\n","      <td>0.0975</td>\n","      <td>48.25</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>Y</td>\n","      <td>216.0</td>\n","    </tr>\n","    <tr>\n","      <th>1090002</th>\n","      <td>35.8475</td>\n","      <td>352.75</td>\n","      <td>24.27</td>\n","      <td>0.4950</td>\n","      <td>23.25</td>\n","      <td>9.285</td>\n","      <td>8.7</td>\n","      <td>0.585</td>\n","      <td>1.8000</td>\n","      <td>-352.75</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>N</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>N</td>\n","      <td>101.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 98 columns</p>\n","</div>"],"text/plain":["                 rev     mou  totmrc      da  ovrmou  ovrrev  vceovr  datovr  \\\n","Customer_ID                                                                    \n","1090001      30.8350  136.75   29.99  0.2475    1.25   0.500     0.5   0.000   \n","1090002      35.8475  352.75   24.27  0.4950   23.25   9.285     8.7   0.585   \n","\n","               roam  change_mou  ...  dwllsize  forgntvl  ethnic  kid0_2  \\\n","Customer_ID                      ...                                       \n","1090001      0.0975       48.25  ...       NaN       1.0       U       U   \n","1090002      1.8000     -352.75  ...       NaN       0.0       N       U   \n","\n","             kid3_5  kid6_10  kid11_15  kid16_17  creditcd  eqpdays  \n","Customer_ID                                                          \n","1090001           U        U         U         U         Y    216.0  \n","1090002           U        U         U         U         N    101.0  \n","\n","[2 rows x 98 columns]"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["# Checkear duplicados en Customer_ID\n","print('Duplicated rows in Customer_ID:', sample_predict['Customer_ID'].duplicated().sum())\n","# Columna Customer_ID transformada a índice\n","df=sample_predict.set_index('Customer_ID')\n","print('Updated index to Customer_ID')\n","print('Rows: ', df.shape[0], '  Columns: ', df.shape[1])\n","df.head(2)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Column Infobase was deleted\n","N° Rows:  10000   Columns:  97\n"]}],"source":["# Eliminar columnas con valor único \n","del(df['infobase'])\n","print(f'Column Infobase was deleted')\n","print('N° Rows: ',df.shape[0], '  Columns: ', df.shape[1])"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total var_cat: 20    Total var_num: 77     Total variables: 97\n"]}],"source":["# Clasificar variables en numéricas y categóricas\n","var_cat = df.select_dtypes(include=['object']).columns.tolist()\n","var_num = df.select_dtypes(include=['int','float']).columns.tolist()\n","print('Total var_cat:', len(var_cat), '   Total var_num:', len(var_num), '    Total variables:', len(var_cat)+len(var_num))"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accent mark deleted"]},{"name":"stdout","output_type":"stream","text":[" \n","\n","Transformed to uppercase \n","\n","AREA word removed \n","\n","UNKNOWN instead UNKW in hnd_webcap category \n","\n","U instead T in dualband category \n","\n"]}],"source":["# Para que todo lo que entren (datos del test, datos nuevos tengan las mismas características), Eliminar los tildes:\n","df[var_cat] = df[var_cat].apply(lambda x: x.apply(lambda y: unidecode(y) if isinstance(y, str) else y))\n","print('Accent mark deleted', '\\n')\n","\n","# Transformar todos los str a letras mayúsculas\n","df[var_cat] = df[var_cat].apply(lambda x: x.str.upper() if x.dtype == 'O' else x)\n","print('Transformed to uppercase', '\\n')\n","\n","# Eliminar ' area' al final de cada string en la columna area\n","df['area'] = df['area'].str.replace(' AREA', '')\n","print('AREA word removed', '\\n')\n","\n","# Cambiar 'UNKW' por 'UNKNOWN', ya que este será un valor a imputar en nulos posteriormente\n","df['hnd_webcap'] = df['hnd_webcap'].replace('UNKW','UNKNOWN')\n","print('UNKNOWN instead UNKW in hnd_webcap category', '\\n')\n","\n","# Reemplazar la categoría 'T' por 'U' en la variable dualband\n","df['dualband'] = df['dualband'].str.replace('T', 'U')\n","df['dualband'] = df['dualband'].str.replace('U', 'UNKNOWN')\n","print('U instead T in dualband category', '\\n')"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["negative_values = ['rev','totmrc','avg6rev','eqpdays']\n","df[negative_values] = df[negative_values].applymap(lambda x: -9999 if x < 0 else x)"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total var_cat: 15    Total var_num: 78     Total variables: 93\n"]}],"source":["# Se agrupan las columnas kids in num_kids\n","list_to_kids=['kid0_2','kid3_5','kid6_10','kid11_15','kid16_17']\n","for i in list_to_kids:\n","    df[i] = df[i].replace({'U': 0, 'Y': 1})\n","\n","df['num_kids'] = df[list_to_kids].sum(axis=1)\n","\n","drop_cols = list(set(list_to_kids))\n","df.drop(columns=drop_cols, inplace=True)   \n","\n","var_cat = df.select_dtypes(include=['object']).columns.tolist()\n","var_num = df.select_dtypes(include=['int','float']).columns.tolist()\n","print('Total var_cat:', len(var_cat), '   Total var_num:', len(var_num), '    Total variables:', len(var_cat)+len(var_num))"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["crslscod modify to one letter instead two \n","\n","Categories were grouped for: ['ethnic', 'crclscod']\n","\n"]}],"source":["#Dejar la variable Credit class code todas con una sola letra\n","df['crclscod'] = df['crclscod'].apply(lambda x: x[0] if x else x)\n","print('crslscod modify to one letter instead two', '\\n')\n","\n","# Agrupar categorias en las variables categoricas\n","list_to_group = ['ethnic', 'crclscod']\n","grouping_dict = {\n","    'crclscod': ['A', 'B', 'C', 'E', 'D', 'Z'],\n","    'ethnic': ['N', 'H', 'S', 'U', 'G','Z','O','I','J','F','B']\n","}\n","for column in list_to_group:\n","    no_group_values = grouping_dict.get(column, [])\n","    df[column] = df[column].apply(lambda x: 'OTHER' if x not in no_group_values and not pd.isna(x) else x)\n","print(f'Categories were grouped for: {list_to_group}\\n') \n","\n","var_cat = df.select_dtypes(include=['object']).columns.tolist()"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Null values transformed to UNKNOWN\n"]}],"source":["# Se imputan los nulos como 'UNKNOWN'\n","var_cat = df.select_dtypes(include=['object']).columns.tolist()\n","for i in var_cat:\n","    df[i].fillna('UNKNOWN', inplace=True)\n","print('Null values transformed to UNKNOWN')"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Null values transformed to -9999\n"]}],"source":["# Columnas numéricas se reemplazan con -9999\n","for i in var_num:\n","   df[i].fillna(-9999, inplace = True)\n","print('Null values transformed to -9999')"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":91,"metadata":{},"output_type":"execute_result"}],"source":["# Check Nulos\n","df.isnull().sum().sum()"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique values for asl_flag: [0 1]\n","Unique values for new_cell: [-9999     1     0]\n","Total var_cat: 13    Total var_num: 80     Total variables: 93\n"]}],"source":["# Si tienen unicamente 2 clases, N: 0, Y: 1 y U or UNKNOWN: -9999\n","mapeo_asl = {'N': 0, 'Y': 1}\n","df['asl_flag'] = df['asl_flag'].replace(mapeo_asl)\n","print(f'Unique values for asl_flag: {df['asl_flag'].unique()}')\n","\n","mapeo_newcell = {'N': 0, 'Y': 1, 'U': -9999}\n","df['new_cell'] = df['new_cell'].replace(mapeo_newcell)\n","print(f'Unique values for new_cell: {df['new_cell'].unique()}')\n","\n","# Actualizar variables en numérica y categóricas\n","var_cat = df.select_dtypes(include=['object']).columns.tolist()\n","var_num = df.select_dtypes(include=['int', 'float']).columns.tolist()\n","print('Total var_cat:', len(var_cat), '   Total var_num:', len(var_num), '    Total variables:', len(var_cat)+len(var_num))"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Rows:  10000   Columns:  171\n","Total var_cat: 0    Total var_num: 80     Total variables: 80\n"]}],"source":["# onehotencoding\n","df = pd.get_dummies(df, columns=var_cat)\n","print('Rows: ', df.shape[0], '  Columns: ', df.shape[1])\n","# Actualizar variables en numérica y categóricas\n","var_cat = df.select_dtypes(include=['object']).columns.tolist()\n","var_num = df.select_dtypes(include=['int', 'float']).columns.tolist()\n","print('Total var_cat:', len(var_cat), '   Total var_num:', len(var_num), '    Total variables:', len(var_cat)+len(var_num))"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["cols_to_drop = ['totmou', 'mou_opkd', 'da', 'phones', 'ovrmou', 'datovr', 'rv', 'models', 'vceovr', 'plcd_vce', 'cc_mou', 'totrev', 'change_rev', 'comp_vce', 'inonemin', 'attempt', 'refurb_new_N', 'avg6qty', 'roam', 'avg6mou', 'truck', 'marital_UNKNOWN', 'ovrrev', 'creditcd_Y', 'comp_dat', 'ethnic_UNKNOWN', 'ownrent_UNKNOWN', 'totcalls', 'forgntvl','ownrent_R', 'HHstatin_G', 'HHstatin_H', 'dwllsize_C', 'dwllsize_D', 'dwllsize_E', 'dwllsize_F', 'dwllsize_G', 'dwllsize_H', 'dwllsize_I', 'dwllsize_J', 'dwllsize_K', 'dwllsize_L', 'dwllsize_M', 'dwllsize_N', 'dwllsize_O', 'ethnic_B', 'creditcd_UNKNOWN']\n","df.drop(columns=cols_to_drop, inplace=True)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["sample_predict = df.copy()"]},{"cell_type":"markdown","metadata":{"id":"cWWJHvZwLpRu"},"source":["# Check model features"]},{"cell_type":"markdown","metadata":{"id":"5c1AMI6qLsLf"},"source":["* Comprobar que tenemos en el dataset preprocesado todas las model features, de lo contrario no podremos hacer predict.\n","* Ordenar las variables en mismo orden que las model features"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"H7Yuoi2ULoxa"},"outputs":[],"source":["# Check features matched features model\n","features_predict = list(sample_predict.columns)\n","model_features = list(model.feature_names_)"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Columnas en dataset predict: 124\n","Variables en modelos: 124\n","¿Match?: True\n"]}],"source":["print('Columnas en dataset predict:',len(features_predict))\n","print('Variables en modelos:',len(model_features))\n","print('¿Match?:', model_features == features_predict)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Variables que faltan el el dataset:\n"," []\n"]}],"source":["missing_features = [i for i in model_features if i not in features_predict]\n","print('Variables que faltan el el dataset:\\n', missing_features)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['rev', 'mou', 'totmrc', 'change_mou', 'drop_vce', 'drop_dat', 'blck_vce', 'blck_dat', 'unan_vce', 'unan_dat', 'plcd_dat', 'recv_vce', 'recv_sms', 'custcare', 'ccrndmou', 'threeway', 'mou_cvce', 'mou_cdat', 'mou_rvce', 'owylis_vce', 'mouowylisv', 'iwylis_vce', 'mouiwylisv', 'peak_vce', 'peak_dat', 'mou_peav', 'mou_pead', 'opk_vce', 'opk_dat', 'mou_opkv', 'drop_blk', 'complete', 'callfwdv', 'callwait', 'months', 'uniqsubs', 'actvsubs', 'new_cell', 'asl_flag', 'adjrev', 'adjmou', 'adjqty', 'avgrev', 'avgmou', 'avgqty', 'avg3mou', 'avg3qty', 'avg3rev', 'avg6rev', 'hnd_price', 'lor', 'adults', 'income', 'numbcars', 'eqpdays', 'num_kids', 'crclscod_A', 'crclscod_B', 'crclscod_C', 'crclscod_D', 'crclscod_E', 'crclscod_OTHER', 'crclscod_Z', 'prizm_social_one_C', 'prizm_social_one_R', 'prizm_social_one_S', 'prizm_social_one_T', 'prizm_social_one_U', 'prizm_social_one_UNKNOWN', 'area_ATLANTIC SOUTH', 'area_CALIFORNIA NORTH', 'area_CENTRAL/SOUTH TEXAS', 'area_CHICAGO', 'area_DALLAS', 'area_DC/MARYLAND/VIRGINIA', 'area_GREAT LAKES', 'area_HOUSTON', 'area_LOS ANGELES', 'area_MIDWEST', 'area_NEW ENGLAND', 'area_NEW YORK CITY', 'area_NORTH FLORIDA', 'area_NORTHWEST/ROCKY MOUNTAIN', 'area_OHIO', 'area_PHILADELPHIA', 'area_SOUTH FLORIDA', 'area_SOUTHWEST', 'area_TENNESSEE', 'dualband_N', 'dualband_UNKNOWN', 'dualband_Y', 'refurb_new_R', 'hnd_webcap_UNKNOWN', 'hnd_webcap_WC', 'hnd_webcap_WCMB', 'ownrent_O', 'dwlltype_M', 'dwlltype_S', 'dwlltype_UNKNOWN', 'marital_A', 'marital_B', 'marital_M', 'marital_S', 'marital_U', 'HHstatin_A', 'HHstatin_B', 'HHstatin_C', 'HHstatin_I', 'HHstatin_UNKNOWN', 'dwllsize_A', 'dwllsize_B', 'dwllsize_UNKNOWN', 'ethnic_F', 'ethnic_G', 'ethnic_H', 'ethnic_I', 'ethnic_J', 'ethnic_N', 'ethnic_O', 'ethnic_OTHER', 'ethnic_S', 'ethnic_U', 'ethnic_Z', 'creditcd_N']\n","['rev', 'mou', 'totmrc', 'change_mou', 'drop_vce', 'drop_dat', 'blck_vce', 'blck_dat', 'unan_vce', 'unan_dat', 'plcd_dat', 'recv_vce', 'recv_sms', 'custcare', 'ccrndmou', 'threeway', 'mou_cvce', 'mou_cdat', 'mou_rvce', 'owylis_vce', 'mouowylisv', 'iwylis_vce', 'mouiwylisv', 'peak_vce', 'peak_dat', 'mou_peav', 'mou_pead', 'opk_vce', 'opk_dat', 'mou_opkv', 'drop_blk', 'complete', 'callfwdv', 'callwait', 'months', 'uniqsubs', 'actvsubs', 'new_cell', 'asl_flag', 'adjrev', 'adjmou', 'adjqty', 'avgrev', 'avgmou', 'avgqty', 'avg3mou', 'avg3qty', 'avg3rev', 'avg6rev', 'hnd_price', 'lor', 'adults', 'income', 'numbcars', 'eqpdays', 'num_kids', 'crclscod_A', 'crclscod_B', 'crclscod_C', 'crclscod_D', 'crclscod_E', 'crclscod_OTHER', 'crclscod_Z', 'prizm_social_one_C', 'prizm_social_one_R', 'prizm_social_one_S', 'prizm_social_one_T', 'prizm_social_one_U', 'prizm_social_one_UNKNOWN', 'area_ATLANTIC SOUTH', 'area_CALIFORNIA NORTH', 'area_CENTRAL/SOUTH TEXAS', 'area_CHICAGO', 'area_DALLAS', 'area_DC/MARYLAND/VIRGINIA', 'area_GREAT LAKES', 'area_HOUSTON', 'area_LOS ANGELES', 'area_MIDWEST', 'area_NEW ENGLAND', 'area_NEW YORK CITY', 'area_NORTH FLORIDA', 'area_NORTHWEST/ROCKY MOUNTAIN', 'area_OHIO', 'area_PHILADELPHIA', 'area_SOUTH FLORIDA', 'area_SOUTHWEST', 'area_TENNESSEE', 'dualband_N', 'dualband_UNKNOWN', 'dualband_Y', 'refurb_new_R', 'hnd_webcap_UNKNOWN', 'hnd_webcap_WC', 'hnd_webcap_WCMB', 'ownrent_O', 'dwlltype_M', 'dwlltype_S', 'dwlltype_UNKNOWN', 'marital_A', 'marital_B', 'marital_M', 'marital_S', 'marital_U', 'HHstatin_A', 'HHstatin_B', 'HHstatin_C', 'HHstatin_I', 'HHstatin_UNKNOWN', 'dwllsize_A', 'dwllsize_B', 'dwllsize_UNKNOWN', 'ethnic_F', 'ethnic_G', 'ethnic_H', 'ethnic_I', 'ethnic_J', 'ethnic_N', 'ethnic_O', 'ethnic_OTHER', 'ethnic_S', 'ethnic_U', 'ethnic_Z', 'creditcd_N']\n"]}],"source":["print(model_features)\n","print(features_predict)"]},{"cell_type":"markdown","metadata":{"id":"MQZVI5GjR815"},"source":["# PREDICT"]},{"cell_type":"markdown","metadata":{"id":"VO5szsPhMygE"},"source":["* predict() y predict_proba()"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["# Reordena variables\n","X_pred = sample_predict[model_features]"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"4a0k5mnKR8WI"},"outputs":[],"source":["predictions = model.predict(X_pred)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["predict = model.predict(sample_predict)[1]"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["predict_proba = model.predict_proba(sample_predict)[:,1][1]"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Clientes que van a abandonar próximo mes (churn=1) 0\n","Probabilidad de abandono: 34.79%\n"]}],"source":["print('Clientes que van a abandonar próximo mes (churn=1)',predict)\n","print('Probabilidad de abandono: {:.2%}'.format(predict_proba))"]},{"cell_type":"markdown","metadata":{"id":"DGcGVB_rJUDz"},"source":["# Guarda predicciones"]},{"cell_type":"markdown","metadata":{"id":"RBexy20LM3sd"},"source":["* Guardar las predicciones en data path. Cada fila debe estar etiquetada con el ID."]},{"cell_type":"code","execution_count":105,"metadata":{"id":"_FzlcWmJJXAN"},"outputs":[],"source":["df_predict= pd.DataFrame(predictions, columns=['churn'], index = X_pred.index)"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["df_predict.to_csv('C:/Users/aalei/Desktop/Marzo 2024/ENTREGA2_COPY/data/telecom_churn_PREDICTIONS.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMI+cgKQx4bIpFRxCNNo4W+","mount_file_id":"1kk2h_aNi6El89qRO-6RUEZBxpLqZiQY-","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
